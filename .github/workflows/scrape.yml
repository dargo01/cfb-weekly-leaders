name: Scrape Weekly Leaders

on:
  schedule:
    # Every 5 minutes on Friday, Saturday, Sunday
    - cron: '*/5 * * * 5,6,0'
  workflow_dispatch:  # allows manual trigger

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run scraper with failsafe
      run: |
        set -e  # stop script if any command fails
        python - <<'EOF'
import json
from espn_parser import scrape
import sys, os

try:
    data = scrape()
    if not data or all(len(v) == 0 for v in data.values()):
        raise ValueError("Scraper returned empty data")
    # Write to a temporary file first
    with open("weekly_temp.json", "w") as f:
        json.dump(data, f, indent=2)
    # Replace old JSON only if scraper succeeded
    os.replace("weekly_temp.json", "weekly.json")
    print("weekly.json updated successfully!")
except Exception as e:
    print(f"Scraper failed: {e}")
    sys.exit(1)
EOF

    - name: Commit and push JSON
      run: |
        git config --local user.name "github-actions[bot]"
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git add weekly.json
        git commit -m "Update weekly.json" || echo "No cha

